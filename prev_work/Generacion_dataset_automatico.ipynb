{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1mbKUH2ACHwSU96G7GhjRLl7mju3HzY3t","authorship_tag":"ABX9TyO9Gs8mVtWnyokTudajgJDG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Los nuevos vídeos van en paralelo a la carretera. Vamos a ver una longitud X de la misma. Vamos a intentar coger X metros. 10 por ejemplo. Calculamos los segundos que tarda en recorrerlo(así calculamos la velocidad). Tamaño en pixeles de la forma del coche, a partir de un umbral X el vehiculo será pesado. \n","\n"],"metadata":{"id":"2gMA9_yrbHix"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"aNIvThwwZdx3","executionInfo":{"status":"ok","timestamp":1672830140866,"user_tz":-60,"elapsed":272,"user":{"displayName":"Ingestion gif","userId":"03172031637053406427"}}},"outputs":[],"source":["#Suponiendo que ya hemos trozeado los vídeos con el notebook llamado procesado_recorte_video_formatoOriginal\n","# Por lo tanto, tendremos un vídeo de 163 segundos. Vamos a hacer un ejemplo de uno de los vídeos y generar un dataset \n","import cv2\n","import numpy as np\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"code","source":["cap = cv2.VideoCapture('/content/drive/MyDrive/INGESTION/DATOS_MEDIDAS/Medidas_Junio_Aoiz/video_220613_15_42_42.MOV')\n","fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n","kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))"],"metadata":{"id":"NyocORcbcxT-","executionInfo":{"status":"ok","timestamp":1672830140866,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ingestion gif","userId":"03172031637053406427"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["cont=0\n","while(cap.isOpened()):\n","    cont=cont+1\n","    ret, frame = cap.read()\n","    #print(ret)\n","    if ret == False: break\n","    if cont>20:\n","        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        # Dibujamos un rectángulo en frame, para señalar el estado\n","        # del área en análisis (movimiento detectado o no detectado)\n","        cv2.rectangle(frame,(0,0),(frame.shape[1],40),(0,0,0),-1)\n","        color = (0, 255, 0)\n","        texto_estado = \"Estado: No se ha detectado movimiento\"\n","        \n","        #print(frame.shape[0],frame.shape[1])\n","        # Especificamos los puntos extremos del área a analizar\n","        area_pts = np.array([[1000,0], [frame.shape[1],0], [frame.shape[1],500], [1000,500]])\n","\n","        # Con ayuda de una imagen auxiliar, determinamos el área sobre la cual actuará el detector de movimiento\n","        imAux = np.zeros(shape=(frame.shape[:2]), dtype=np.uint8)\n","        imAux = cv2.drawContours(imAux, [area_pts], -1, (255), -1)\n","        image_area = cv2.bitwise_and(gray, gray, mask=imAux)\n","        \n","        # Obtendremos la imagen binaria donde la región en blanco que representa la existencia de movimiento\n","        fgmask_1 = fgbg.apply(image_area)\n","        fgmask_1 = cv2.morphologyEx(fgmask_1, cv2.MORPH_OPEN, kernel)\n","        fgmask_1 = cv2.dilate(fgmask_1, None, iterations=2)\n","        \n","        # Encontramos los contornos presentes en fgmask, para luego basándonos\n","        # en su área poder determina si existe movimiento\n","        cnts_1 = cv2.findContours(fgmask_1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n","        \n","        if len(cnts_1)>0:\n","            for cnt in cnts_1:\n","                if cv2.contourArea(cnt) > 500  :\n","                    x, y, w, h = cv2.boundingRect(cnt)\n","                    cv2.rectangle(frame, (x,y), (x+w, y+h),(0,255,0), 2)\n","                    texto_estado = \"Movimiento!\"\n","                    color = (0, 0, 255)\n","            \n","            # Visuzalizamos el rectangulo alrededor del área que vamos a analizary el estado de la detección de movimiento \n","            cv2.drawContours(frame, [area_pts], -1, color, 2)\n","            cv2.putText(frame, texto_estado , (10, 750), cv2.FONT_HERSHEY_SIMPLEX, 1, color,2) \n","            cv2_imshow(frame)\n","            cv2.waitKey(0)\n","cap.release()\n","cv2.destroyAllWindows()"],"metadata":{"id":"76wNTrmec_Dd","executionInfo":{"status":"ok","timestamp":1672830140867,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ingestion gif","userId":"03172031637053406427"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Con el codigo anterior ya derectamos el recorrido del coche en un area determinada. Viene a ser un rectangulo de aproximagamente 500x920 pìxeles. Hemos colocado el limite de área para un objeto detectado en 500 píxeles. Así evitamos la aparición de agentes externos como particulas o pajaros. \n","\n","Ahora solo falta saber a cuantos metros equivalen en la realidad el área abarcada. Contar el número de frames que tarda el coche en recorrer esa distancia y tendríamos la velocidad.\n","\n","Umbrales preliminares viendo el vídeo:\n","\n","  -Vehículos ligeros, varían entre 1700 y 2200 píxels cuadrados. Para cubrirnos, vamos a aumentar este umbral de 1500 a 2500.\n","\n","  -Motocicletas:Todo lo que esté por encima de 500 y menor a 1500 será una moto.\n","\n","  -Vehículos pesados: Todo lo que esté por encima de 2500\n","\n","Para el dataset tambíen es interesante los segundos de vídeo que estamos viendo a este coche. De la misma forma que con la velocidad, sabiendo los frames que cubrimos podemos calcular facilmente los segundos de vídeo a los que corresponde.\n"],"metadata":{"id":"kg2ymF1avO6Y"}},{"cell_type":"code","source":["frame=0\n","while(cap.isOpened()):\n","    frame = frame + 1\n","    ret, frame_video = cap.read()\n","    #print(ret)\n","    if ret == False: break\n","    if frame>20:\n","        gray = cv2.cvtColor(frame_video, cv2.COLOR_BGR2GRAY)\n","        # Dibujamos un rectángulo en frame, para señalar el estado\n","        # del área en análisis (movimiento detectado o no detectado)\n","        cv2.rectangle(frame_video,(0,0),(frame_video.shape[1],40),(0,0,0),-1)\n","        color = (0, 255, 0)\n","        texto_estado = \"Estado: No se ha detectado movimiento\"\n","        \n","        #print(frame.shape[0],frame.shape[1])\n","        # Especificamos los puntos extremos del área a analizar\n","        area_pts = np.array([[1000,0], [frame_video.shape[1],0], [frame_video.shape[1],500], [1000,500]])\n","\n","        # Con ayuda de una imagen auxiliar, determinamos el área sobre la cual actuará el detector de movimiento\n","        imAux = np.zeros(shape=(frame_video.shape[:2]), dtype=np.uint8)\n","        imAux = cv2.drawContours(imAux, [area_pts], -1, (255), -1)\n","        image_area = cv2.bitwise_and(gray, gray, mask=imAux)\n","        \n","        # Obtendremos la imagen binaria donde la región en blanco que representa la existencia de movimiento\n","        fgmask_1 = fgbg.apply(image_area)\n","        fgmask_1 = cv2.morphologyEx(fgmask_1, cv2.MORPH_OPEN, kernel)\n","        fgmask_1 = cv2.dilate(fgmask_1, None, iterations=2)\n","        \n","        # Encontramos los contornos presentes en fgmask, para luego basándonos\n","        # en su área poder determina si existe movimiento\n","        cnts_1 = cv2.findContours(fgmask_1, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n","        \n","        if len(cnts_1)>0:\n","            for cnt in cnts_1:\n","                if cv2.contourArea(cnt) > 500 and cv2.contourArea(cnt)<1500  :\n","                    x, y, w, h = cv2.boundingRect(cnt)\n","                    cv2.rectangle(frame_video, (x,y), (x+w, y+h),(0,255,0), 2)\n","                    texto_estado = \"Movimiento moto!\"\n","                    color = (0, 0, 255)\n","                    tipo_vehiculo = \"moto\"\n","                if cv2.contourArea(cnt) > 1500 and cv2.contourArea(cnt) < 2500  :\n","                    x, y, w, h = cv2.boundingRect(cnt)\n","                    cv2.rectangle(frame_video, (x,y), (x+w, y+h),(0,255,0), 2)\n","                    texto_estado = \"Movimiento: coche!\"\n","                    color = (0, 0, 255)\n","                    tipo_vehiculo = \"coche\"\n","                if cv2.contourArea(cnt) > 2500 :\n","                    x, y, w, h = cv2.boundingRect(cnt)\n","                    cv2.rectangle(frame_video, (x,y), (x+w, y+h),(0,255,0), 2)\n","                    texto_estado = \"Movimiento: camión!\"\n","                    color = (0, 0, 255)\n","                    tipo_vehiculo = \"camión\"\n","            \n","            # Visuzalizamos el rectangulo alrededor del área que vamos a analizary el estado de la detección de movimiento \n","            cv2.drawContours(frame_video, [area_pts], -1, color, 2)\n","            cv2.putText(frame_video, texto_estado , (10, 750), cv2.FONT_HERSHEY_SIMPLEX, 1, color,2) \n","            cv2.imshow(\"frame\",frame_video)\n","            cv2.waitKey(0)\n","cap.release()\n","cv2.destroyAllWindows()"],"metadata":{"id":"QpFWdTyExEwc","executionInfo":{"status":"ok","timestamp":1672830144209,"user_tz":-60,"elapsed":252,"user":{"displayName":"Ingestion gif","userId":"03172031637053406427"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Ahora mismo no tenemos en cuenta si se cruzasen dos coches en el área determinada. Para tener esto en cuenta nos vamos a basar en el siguiente script que consigue el \"tracking\" de una persona pero aplicado para un coche. \n","https://broutonlab.com/blog/opencv-object-tracking"],"metadata":{"id":"Bfh6en2xANF6"}}]}